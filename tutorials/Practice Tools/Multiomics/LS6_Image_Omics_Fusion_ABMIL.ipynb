{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def29c4a",
   "metadata": {},
   "source": [
    "\n",
    "# Learning Series #6 — Image × Omics Fusion (ABMIL demo)\n",
    "\n",
    "This notebook trains an **Attention-based MIL** model on tile-level features with **omics-derived labels** (CD274_high or KRAS_mut).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d190d",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "# !pip install pandas numpy scikit-learn matplotlib\n",
    "import os, json, math, random\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 140\n",
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "\n",
    "OUT_DIR = \"outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "print(\"Saving outputs to:\", OUT_DIR)\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85948685",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load data\n",
    "Change `tiles_path`, `labels_path`, and `splits_path` if using your own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37219d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tiles_path = \"example_tiles.csv\"\n",
    "labels_path = \"example_labels.csv\"\n",
    "splits_path = \"example_splits.csv\"\n",
    "\n",
    "tiles = pd.read_csv(tiles_path)\n",
    "labels = pd.read_csv(labels_path)\n",
    "splits = pd.read_csv(splits_path)\n",
    "\n",
    "# Basic checks\n",
    "assert {\"tile_id\",\"sample_id\"}.issubset(tiles.columns)\n",
    "feat_cols = [c for c in tiles.columns if c.startswith(\"f\")]\n",
    "assert len(feat_cols) > 0, \"No feature columns starting with 'f' found\"\n",
    "assert \"sample_id\" in labels.columns and \"CD274_high\" in labels.columns and \"KRAS_mut\" in labels.columns\n",
    "assert \"sample_id\" in splits.columns and \"split\" in splits.columns\n",
    "\n",
    "print(\"Tiles:\", tiles.shape, \"| Labels:\", labels.shape, \"| Splits:\", splits[\"split\"].value_counts().to_dict())\n",
    "tiles.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c9d69",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Build MIL bags\n",
    "One bag = all tiles for a `sample_id`. Choose your label column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LABEL_COL = \"CD274_high\"   # or \"KRAS_mut\"\n",
    "\n",
    "# Assemble bags: list of (sample_id, np.array[n_tiles, feat_dim])\n",
    "bags = []\n",
    "for sid, df in tiles.groupby(\"sample_id\"):\n",
    "    feats = df[feat_cols].values.astype(\"float32\")\n",
    "    bags.append((sid, feats))\n",
    "\n",
    "# Map labels\n",
    "lab_map = labels.set_index(\"sample_id\")[LABEL_COL].to_dict()\n",
    "split_map = splits.set_index(\"sample_id\")[\"split\"].to_dict()\n",
    "\n",
    "def split_bags(bags):\n",
    "    tr, va, te = [], [], []\n",
    "    for sid, feats in bags:\n",
    "        if sid not in lab_map or sid not in split_map: \n",
    "            continue\n",
    "        y = int(lab_map[sid])\n",
    "        s = split_map[sid]\n",
    "        if s == \"train\": tr.append((sid, feats, y))\n",
    "        elif s == \"val\": va.append((sid, feats, y))\n",
    "        else: te.append((sid, feats, y))\n",
    "    return tr, va, te\n",
    "\n",
    "train_bags, val_bags, test_bags = split_bags(bags)\n",
    "len(train_bags), len(val_bags), len(test_bags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae4b98f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) ABMIL model\n",
    "Simple attention pooling (Ilse et al. 2018). Batch size = 1 bag for simplicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ABMIL(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=128):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(hid_dim, hid_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hid_dim, 1)\n",
    "        )\n",
    "        self.clf = nn.Linear(hid_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [n_tiles, in_dim]\n",
    "        H = self.embed(x)              # [n_tiles, hid_dim]\n",
    "        a = self.attn(H)               # [n_tiles, 1]\n",
    "        w = torch.softmax(a.squeeze(-1), dim=0)  # [n_tiles]\n",
    "        M = torch.sum(H * w.unsqueeze(-1), dim=0)  # [hid_dim]\n",
    "        logit = self.clf(M).squeeze(0)  # scalar\n",
    "        return logit, w, M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db9e0a6",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Training utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BagDataset(Dataset):\n",
    "    def __init__(self, bag_tuples):\n",
    "        self.bag_tuples = bag_tuples  # list of (sid, feats, y)\n",
    "\n",
    "    def __len__(self): return len(self.bag_tuples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid, feats, y = self.bag_tuples[idx]\n",
    "        return sid, torch.from_numpy(feats), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "def run_epoch(model, loader, opt=None):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    y_true, y_score, losses = [], [], []\n",
    "    for sid, feats, y in loader:\n",
    "        feats = feats[0]  # batch_size=1\n",
    "        y = y[0]\n",
    "        if is_train: opt.zero_grad()\n",
    "        logit, w, M = model(feats)\n",
    "        loss = F.binary_cross_entropy_with_logits(logit, y)\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            opt.step()\n",
    "        prob = torch.sigmoid(logit).detach().cpu().item()\n",
    "        y_true.append(int(y.item()))\n",
    "        y_score.append(prob)\n",
    "        losses.append(loss.item())\n",
    "    auroc = roc_auc_score(y_true, y_score) if len(set(y_true)) > 1 else float(\"nan\")\n",
    "    acc = accuracy_score(y_true, [1 if s>=0.5 else 0 for s in y_score])\n",
    "    return np.mean(losses), auroc, acc\n",
    "\n",
    "def evaluate_and_save_curves(y_true, y_score, name):\n",
    "    if len(set(y_true)) < 2:\n",
    "        return\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(f\"ROC — {name}\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"roc_curve_{name}.png\"), dpi=300)\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"roc_curve_{name}.svg\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1593c3",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_dim = len(feat_cols)\n",
    "model = ABMIL(in_dim=in_dim, hid_dim=128)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "train_loader = DataLoader(BagDataset(train_bags), batch_size=1, shuffle=True)\n",
    "val_loader   = DataLoader(BagDataset(val_bags), batch_size=1, shuffle=False)\n",
    "test_loader  = DataLoader(BagDataset(test_bags), batch_size=1, shuffle=False)\n",
    "\n",
    "EPOCHS = 8\n",
    "history = {\"train_loss\": [], \"val_loss\": [], \"val_auroc\": [], \"val_acc\": []}\n",
    "\n",
    "best_val = -1\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, _, _ = run_epoch(model, train_loader, opt)\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_auroc, val_acc = run_epoch(model, val_loader, None)\n",
    "    history[\"train_loss\"].append(tr_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_auroc\"].append(val_auroc)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "    if not math.isnan(val_auroc) and val_auroc > best_val:\n",
    "        best_val = val_auroc\n",
    "        best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={tr_loss:.4f} val_loss={val_loss:.4f} val_auroc={val_auroc:.3f} val_acc={val_acc:.3f}\")\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "torch.save(model.state_dict(), os.path.join(OUT_DIR, \"model.pt\"))\n",
    "\n",
    "# Loss curve\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "plt.plot(history[\"train_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_loss\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"BCE loss\")\n",
    "plt.title(\"Training/Validation Loss\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"loss_curve.png\"), dpi=300)\n",
    "plt.savefig(os.path.join(OUT_DIR, \"loss_curve.svg\"))\n",
    "plt.show()\n",
    "\n",
    "# Final eval on val + test and ROC curves\n",
    "def collect_scores(loader):\n",
    "    y_true, y_score = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sid, feats, y in loader:\n",
    "            feats = feats[0]\n",
    "            y = y[0]\n",
    "            logit, w, _ = model(feats)\n",
    "            prob = torch.sigmoid(logit).item()\n",
    "            y_true.append(int(y.item()))\n",
    "            y_score.append(prob)\n",
    "    return y_true, y_score\n",
    "\n",
    "y_val, s_val = collect_scores(val_loader)\n",
    "y_test, s_test = collect_scores(test_loader)\n",
    "evaluate_and_save_curves(y_val, s_val, f\"{LABEL_COL}_val\")\n",
    "evaluate_and_save_curves(y_test, s_test, f\"{LABEL_COL}_test\")\n",
    "\n",
    "metrics = {\n",
    "    \"label\": LABEL_COL,\n",
    "    \"val\": {\n",
    "        \"auroc\": float(roc_auc_score(y_val, s_val)) if len(set(y_val))>1 else None,\n",
    "        \"acc\": float(accuracy_score(y_val, [1 if z>=0.5 else 0 for z in s_val]))\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"auroc\": float(roc_auc_score(y_test, s_test)) if len(set(y_test))>1 else None,\n",
    "        \"acc\": float(accuracy_score(y_test, [1 if z>=0.5 else 0 for z in s_test]))\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d261321",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Export attention for interpretability\n",
    "Saves tile-level attention per selected samples for downstream overlays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_attention_for_samples(sample_ids, top_k=3):\n",
    "    exported = []\n",
    "    for sid in sample_ids[:top_k]:\n",
    "        df_s = tiles[tiles[\"sample_id\"] == sid].reset_index(drop=True)\n",
    "        feats = torch.from_numpy(df_s[feat_cols].values.astype(\"float32\"))\n",
    "        with torch.no_grad():\n",
    "            _, w, _ = model(feats)\n",
    "        attn = w.detach().cpu().numpy().reshape(-1)\n",
    "        out = df_s[[\"tile_id\",\"sample_id\",\"x\",\"y\"]].copy()\n",
    "        out[\"attention\"] = attn\n",
    "        out = out.sort_values(\"attention\", ascending=False)\n",
    "        out_path = os.path.join(OUT_DIR, f\"attention_{sid}.csv\")\n",
    "        out.to_csv(out_path, index=False)\n",
    "        exported.append(out_path)\n",
    "    return exported\n",
    "\n",
    "# Example: export top-2 samples by predicted probability on test set\n",
    "sample_scores = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for sid, feats, y in test_loader:\n",
    "        feats = feats[0]\n",
    "        logit, w, _ = model(feats)\n",
    "        prob = torch.sigmoid(logit).item()\n",
    "        sample_scores.append((sid[0], prob))\n",
    "\n",
    "sample_scores = sorted(sample_scores, key=lambda x: x[1], reverse=True)\n",
    "selected = [sid for sid,_ in sample_scores[:2]]\n",
    "paths = export_attention_for_samples(selected, top_k=2)\n",
    "paths\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
